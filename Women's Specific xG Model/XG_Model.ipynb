{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsbombpy import sb\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score,cross_val_predict, KFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import log_loss, roc_auc_score, classification_report\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shot_statsbomb_xg         1.000000\n",
      "shot_type_Penalty         0.782955\n",
      "location_[108.1, 40.1]    0.593886\n",
      "shot_outcome_Goal         0.535508\n",
      "angle_to_goal             0.513792\n",
      "                            ...   \n",
      "shot_outcome_Off T       -0.123822\n",
      "duration                 -0.154096\n",
      "under_pressure           -0.163376\n",
      "distance_to_goal         -0.450499\n",
      "shot_type_Open Play      -0.580484\n",
      "Name: shot_statsbomb_xg, Length: 9759, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('Statsbomb Data.csv')\n",
    "\n",
    "# Function to handle unhashable types for one-hot encoding\n",
    "def make_hashable(x):\n",
    "    if isinstance(x, list):\n",
    "        return str(x)  # Convert lists to string to make them hashable\n",
    "    return x\n",
    "\n",
    "# Apply this function to all columns that might contain unhashable types\n",
    "for col in data.columns:\n",
    "    data[col] = data[col].apply(make_hashable)\n",
    "\n",
    "# Define functions to calculate additional metrics if relevant\n",
    "def calculate_distance_to_goal(shot_location):\n",
    "    if isinstance(shot_location, str):\n",
    "        shot_location = eval(shot_location)  # Convert string back to list\n",
    "    goal_x, goal_y = 120, 40  # Coordinates of the center of the goal line\n",
    "    return np.sqrt((goal_x - shot_location[0])**2 + (goal_y - shot_location[1])**2)\n",
    "\n",
    "def calculate_angle_to_goal(shot_location):\n",
    "    if isinstance(shot_location, str):\n",
    "        shot_location = eval(shot_location)  # Convert string back to list\n",
    "    goal_y1, goal_y2 = 36, 44  # y-coordinates of the goalposts\n",
    "    angle1 = np.arctan2(goal_y1 - shot_location[1], 120 - shot_location[0])\n",
    "    angle2 = np.arctan2(goal_y2 - shot_location[1], 120 - shot_location[0])\n",
    "    return abs(angle1 - angle2)\n",
    "\n",
    "# Calculate metrics and add to data\n",
    "data['distance_to_goal'] = data['location'].apply(calculate_distance_to_goal)\n",
    "data['angle_to_goal'] = data['location'].apply(calculate_angle_to_goal)\n",
    "\n",
    "# Convert all categorical variables using one-hot encoding\n",
    "categorical_features = data.select_dtypes(include=['object']).columns.tolist()\n",
    "data = pd.get_dummies(data, columns=categorical_features, drop_first=True)\n",
    "\n",
    "# Calculate correlations with 'shot_statsbomb_xg'\n",
    "correlation_matrix = data.corr()\n",
    "statsbomb_xg_correlations = correlation_matrix['shot_statsbomb_xg'].sort_values(ascending=False)\n",
    "\n",
    "# Print the correlations\n",
    "print(statsbomb_xg_correlations)\n",
    "\n",
    "# Save to CSV if needed\n",
    "statsbomb_xg_correlations.to_csv('complete_correlation_with_statsbomb_xg.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE TO EXTRACT DATA\n",
    "# # get a list of all competitions\n",
    "competitions = sb.competitions()\n",
    "competitions = competitions[competitions['competition_gender'] == 'female']\n",
    "\n",
    "#using the season id and competition id from competitions, get all match ids from competition\n",
    "matches = sb.matches(competition_id=72, season_id=107)\n",
    "match_ids = matches['match_id']\n",
    "match_ids\n",
    "\n",
    "# filter shots data to only include columns of interest\n",
    "cols = ['id', 'player', 'team', 'minute', 'location', 'shot_type', 'shot_outcome', 'under_pressure', 'shot_body_part', 'shot_end_location',\n",
    "        'shot_first_time', 'shot_freeze_frame', 'shot_key_pass_id', 'shot_one_on_one', 'shot_outcome', 'shot_technique', 'shot_first_time', 'shot_deflected', 'pass_assisted_shot_id', \n",
    "        'pass_shot_assist', 'pass_goal_assist', 'pass_type','pass_end_location', 'pass_assisted_shot_id', 'goalkeeper_end_location', 'goalkeeper_position',\n",
    "        'goalkeeper_outcome', 'goalkeeper_technique', 'period', 'play_pattern', 'shot_statsbomb_xg']\n",
    "\n",
    "#for each match, get all shots data\n",
    "shots_data = pd.DataFrame()\n",
    "for i in range(0, len(match_ids)):\n",
    "    #try:\n",
    "    print(match_ids[i])\n",
    "    match_events = sb.events(match_id=match_ids[i])\n",
    "    shots = match_events[match_events['type'] == 'Shot']\n",
    "    #shots = shots[cols]\n",
    "    shots_data = pd.concat([shots_data, shots])\n",
    "shots_df = pd.DataFrame(shots_data)\n",
    "shots_df.to_csv(\"shots_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>possession_team</th>\n",
       "      <th>player</th>\n",
       "      <th>position</th>\n",
       "      <th>location</th>\n",
       "      <th>distance_to_goal</th>\n",
       "      <th>angle_to_goal</th>\n",
       "      <th>shot_speed</th>\n",
       "      <th>play_pattern</th>\n",
       "      <th>shot_type</th>\n",
       "      <th>minute</th>\n",
       "      <th>period</th>\n",
       "      <th>under_pressure</th>\n",
       "      <th>shot_body_part</th>\n",
       "      <th>shot_one_on_one</th>\n",
       "      <th>shot_first_time</th>\n",
       "      <th>shot_technique</th>\n",
       "      <th>statsbomb_xg</th>\n",
       "      <th>shot_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Morocco Women's</td>\n",
       "      <td>Ibtissam Jraïdi</td>\n",
       "      <td>Forward</td>\n",
       "      <td>[115.6, 23.1]</td>\n",
       "      <td>17.75387</td>\n",
       "      <td>6.09144</td>\n",
       "      <td>37.28771</td>\n",
       "      <td>Regular Play</td>\n",
       "      <td>Open Play</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Foot</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0.011643</td>\n",
       "      <td>Saved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Colombia Women's</td>\n",
       "      <td>Mayra Tatiana Ramírez Ramírez</td>\n",
       "      <td>Forward</td>\n",
       "      <td>[113.6, 54.5]</td>\n",
       "      <td>15.57562</td>\n",
       "      <td>11.55180</td>\n",
       "      <td>22.60042</td>\n",
       "      <td>Regular Play</td>\n",
       "      <td>Open Play</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>Foot</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0.017579</td>\n",
       "      <td>Off T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Morocco Women's</td>\n",
       "      <td>Ibtissam Jraïdi</td>\n",
       "      <td>Forward</td>\n",
       "      <td>[107.8, 33.7]</td>\n",
       "      <td>13.87083</td>\n",
       "      <td>26.51428</td>\n",
       "      <td>11.62217</td>\n",
       "      <td>Regular Play</td>\n",
       "      <td>Open Play</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Head</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0.062036</td>\n",
       "      <td>Saved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Colombia Women's</td>\n",
       "      <td>María Catalina Usme Pineda</td>\n",
       "      <td>Midfielder</td>\n",
       "      <td>[103.2, 74.4]</td>\n",
       "      <td>38.01381</td>\n",
       "      <td>4.90953</td>\n",
       "      <td>18.59899</td>\n",
       "      <td>From Free Kick</td>\n",
       "      <td>Free Kick</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Foot</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0.005588</td>\n",
       "      <td>Off T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Colombia Women's</td>\n",
       "      <td>Daniela Montoya Quiróz</td>\n",
       "      <td>Midfielder</td>\n",
       "      <td>[111.0, 39.3]</td>\n",
       "      <td>9.05539</td>\n",
       "      <td>43.83945</td>\n",
       "      <td>429.42998</td>\n",
       "      <td>From Throw In</td>\n",
       "      <td>Open Play</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>Head</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0.169690</td>\n",
       "      <td>Saved</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    possession_team                         player    position       location  \\\n",
       "0   Morocco Women's                Ibtissam Jraïdi     Forward  [115.6, 23.1]   \n",
       "1  Colombia Women's  Mayra Tatiana Ramírez Ramírez     Forward  [113.6, 54.5]   \n",
       "2   Morocco Women's                Ibtissam Jraïdi     Forward  [107.8, 33.7]   \n",
       "3  Colombia Women's     María Catalina Usme Pineda  Midfielder  [103.2, 74.4]   \n",
       "4  Colombia Women's         Daniela Montoya Quiróz  Midfielder  [111.0, 39.3]   \n",
       "\n",
       "   distance_to_goal  angle_to_goal  shot_speed    play_pattern  shot_type  \\\n",
       "0          17.75387        6.09144    37.28771    Regular Play  Open Play   \n",
       "1          15.57562       11.55180    22.60042    Regular Play  Open Play   \n",
       "2          13.87083       26.51428    11.62217    Regular Play  Open Play   \n",
       "3          38.01381        4.90953    18.59899  From Free Kick  Free Kick   \n",
       "4           9.05539       43.83945   429.42998   From Throw In  Open Play   \n",
       "\n",
       "   minute  period  under_pressure shot_body_part  shot_one_on_one  \\\n",
       "0       0       1           False           Foot             True   \n",
       "1      10       1            True           Foot            False   \n",
       "2      12       1           False           Head            False   \n",
       "3      16       1           False           Foot            False   \n",
       "4      19       1            True           Head            False   \n",
       "\n",
       "   shot_first_time shot_technique  statsbomb_xg shot_outcome  \n",
       "0            False         Normal      0.011643        Saved  \n",
       "1             True         Normal      0.017579        Off T  \n",
       "2            False         Normal      0.062036        Saved  \n",
       "3            False         Normal      0.005588        Off T  \n",
       "4            False         Normal      0.169690        Saved  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Model dataset from statsbomb data\n",
    "# Load the dataset\n",
    "file_path = 'Statsbomb Data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Define the goal post coordinates considering the goal width\n",
    "goal_center_x = 120\n",
    "goal_center_y = 40.3\n",
    "goal_width = 7.32\n",
    "\n",
    "left_goal_post_x = 120\n",
    "left_goal_post_y = goal_center_y - (goal_width / 2)\n",
    "right_goal_post_x = 120\n",
    "right_goal_post_y = goal_center_y + (goal_width / 2)\n",
    "\n",
    "# Function to calculate the distance to goal\n",
    "def calculate_distance_to_goal(location):\n",
    "    x, y = eval(location)\n",
    "    return np.sqrt((goal_center_x - x) ** 2 + (goal_center_y - y) ** 2)\n",
    "\n",
    "# Function to calculate the angle to both goal posts\n",
    "def calculate_angle_to_goal_posts(location):\n",
    "    x, y = eval(location)\n",
    "    left_post_angle = np.arctan2(left_goal_post_y - y, left_goal_post_x - x)\n",
    "    right_post_angle = np.arctan2(right_goal_post_y - y, right_goal_post_x - x)\n",
    "    return np.degrees(right_post_angle - left_post_angle)\n",
    "\n",
    "# Function to normalize the shot body part\n",
    "def normalize_shot_body_part(shot_body_part):\n",
    "    if shot_body_part in ['Left Foot', 'Right Foot']:\n",
    "        return 'Foot'\n",
    "    return shot_body_part\n",
    "\n",
    "# Function to classify positions\n",
    "def classify_position(position):\n",
    "    forward_positions = [\n",
    "        'Center Forward', 'Left Wing', 'Right Wing', 'Left Center Forward', 'Right Center Forward'\n",
    "    ]\n",
    "    midfielder_positions = [\n",
    "        'Center Attacking Midfield', 'Left Midfield', 'Right Midfield', 'Left Center Midfield', \n",
    "        'Right Center Midfield', 'Center Defensive Midfield', 'Left Defensive Midfield', \n",
    "        'Right Defensive Midfield', 'Left Attacking Midfield', 'Right Attacking Midfield'\n",
    "    ]\n",
    "    defender_positions = [\n",
    "        'Left Back', 'Right Back', 'Left Center Back', 'Right Center Back', 'Center Back', \n",
    "        'Left Wing Back', 'Right Wing Back'\n",
    "    ]\n",
    "    goalkeeper_positions = ['Goalkeeper']\n",
    "\n",
    "    if position in forward_positions:\n",
    "        return 'Forward'\n",
    "    elif position in midfielder_positions:\n",
    "        return 'Midfielder'\n",
    "    elif position in defender_positions:\n",
    "        return 'Defender'\n",
    "    elif position in goalkeeper_positions:\n",
    "        return 'Goalkeeper'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "# Select and process the relevant columns\n",
    "processed_data = data[['location', 'play_pattern', 'shot_type', 'minute', 'period', 'under_pressure', 'shot_one_on_one', 'shot_first_time', 'shot_technique', 'shot_statsbomb_xg', 'player', 'position', 'possession_team', 'shot_outcome']].copy()\n",
    "\n",
    "# Calculate distance to goal\n",
    "processed_data['distance_to_goal'] = data['location'].apply(calculate_distance_to_goal).round(5)\n",
    "\n",
    "# Calculate angle to goal posts\n",
    "processed_data['angle_to_goal'] = data['location'].apply(calculate_angle_to_goal_posts).round(5)\n",
    "\n",
    "# Calculate shot speed\n",
    "processed_data['shot_speed'] = (processed_data['distance_to_goal'] / data['duration']).round(5)\n",
    "\n",
    "# Normalize shot body part\n",
    "processed_data['shot_body_part'] = data['shot_body_part'].apply(normalize_shot_body_part)\n",
    "\n",
    "# Classify positions\n",
    "processed_data['position'] = data['position'].apply(classify_position)\n",
    "\n",
    "# Rename the statsbomb_xg column\n",
    "processed_data.rename(columns={'shot_statsbomb_xg': 'statsbomb_xg'}, inplace=True)\n",
    "\n",
    "# Reorder columns as specified, adding team (possession_team) at the start\n",
    "processed_data = processed_data[['possession_team', 'player', 'position', 'location', 'distance_to_goal', 'angle_to_goal', 'shot_speed', 'play_pattern', 'shot_type', 'minute', 'period', 'under_pressure', 'shot_body_part', 'shot_one_on_one', 'shot_first_time', 'shot_technique', 'statsbomb_xg', 'shot_outcome']]\n",
    "\n",
    "# Save the processed data to a new CSV file\n",
    "processed_data.to_csv('model_data.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the processed dataset\n",
    "processed_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Log Loss (10-fold CV): 0.3054622738179438\n",
      "Logistic Regression - ROC AUC Score (10-fold CV): 0.9386043943269007\n",
      "Logistic Regression - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.88      0.93      1496\n",
      "           1       0.48      0.88      0.62       184\n",
      "\n",
      "    accuracy                           0.88      1680\n",
      "   macro avg       0.73      0.88      0.77      1680\n",
      "weighted avg       0.93      0.88      0.90      1680\n",
      "\n",
      "XGBoost - Log Loss (10-fold CV): 0.2421192114885202\n",
      "XGBoost - ROC AUC Score (10-fold CV): 0.9329698035340619\n",
      "XGBoost - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1496\n",
      "           1       0.70      0.60      0.65       184\n",
      "\n",
      "    accuracy                           0.93      1680\n",
      "   macro avg       0.83      0.79      0.80      1680\n",
      "weighted avg       0.92      0.93      0.93      1680\n",
      "\n",
      "CatBoost - Log Loss (10-fold CV): 0.1698962461984756\n",
      "CatBoost - ROC AUC Score (10-fold CV): 0.9447584863985119\n",
      "CatBoost - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      1496\n",
      "           1       0.73      0.65      0.68       184\n",
      "\n",
      "    accuracy                           0.93      1680\n",
      "   macro avg       0.84      0.81      0.82      1680\n",
      "weighted avg       0.93      0.93      0.93      1680\n",
      "\n",
      "Random Forest - Log Loss (10-fold CV): 0.22852481838500643\n",
      "Random Forest - ROC AUC Score (10-fold CV): 0.9391693065566148\n",
      "Random Forest - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1496\n",
      "           1       0.71      0.55      0.62       184\n",
      "\n",
      "    accuracy                           0.93      1680\n",
      "   macro avg       0.83      0.76      0.79      1680\n",
      "weighted avg       0.92      0.93      0.92      1680\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 166, number of negative: 1346\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000467 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 953\n",
      "[LightGBM] [Info] Number of data points in the train set: 1512, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.109788 -> initscore=-2.092905\n",
      "[LightGBM] [Info] Start training from score -2.092905\n",
      "[LightGBM] [Info] Number of positive: 166, number of negative: 1346\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000557 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 953\n",
      "[LightGBM] [Info] Number of data points in the train set: 1512, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.109788 -> initscore=-2.092905\n",
      "[LightGBM] [Info] Start training from score -2.092905\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 166, number of negative: 1346\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000375 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 952\n",
      "[LightGBM] [Info] Number of data points in the train set: 1512, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.109788 -> initscore=-2.092905\n",
      "[LightGBM] [Info] Start training from score -2.092905\n",
      "[LightGBM] [Info] Number of positive: 166, number of negative: 1346\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 953\n",
      "[LightGBM] [Info] Number of data points in the train set: 1512, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.109788 -> initscore=-2.092905\n",
      "[LightGBM] [Info] Start training from score -2.092905\n",
      "[LightGBM] [Info] Number of positive: 166, number of negative: 1346\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000320 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 953\n",
      "[LightGBM] [Info] Number of data points in the train set: 1512, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.109788 -> initscore=-2.092905\n",
      "[LightGBM] [Info] Start training from score -2.092905\n",
      "[LightGBM] [Info] Number of positive: 166, number of negative: 1346\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000346 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 952\n",
      "[LightGBM] [Info] Number of data points in the train set: 1512, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.109788 -> initscore=-2.092905\n",
      "[LightGBM] [Info] Start training from score -2.092905\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 165, number of negative: 1347\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000367 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 1512, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.109127 -> initscore=-2.099690\n",
      "[LightGBM] [Info] Start training from score -2.099690\n",
      "[LightGBM] [Info] Number of positive: 165, number of negative: 1347\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000400 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 950\n",
      "[LightGBM] [Info] Number of data points in the train set: 1512, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.109127 -> initscore=-2.099690\n",
      "[LightGBM] [Info] Start training from score -2.099690\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 165, number of negative: 1347\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000374 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 947\n",
      "[LightGBM] [Info] Number of data points in the train set: 1512, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.109127 -> initscore=-2.099690\n",
      "[LightGBM] [Info] Start training from score -2.099690\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 165, number of negative: 1347\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000414 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 943\n",
      "[LightGBM] [Info] Number of data points in the train set: 1512, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.109127 -> initscore=-2.099690\n",
      "[LightGBM] [Info] Start training from score -2.099690\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 166, number of negative: 1346\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000400 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 953\n",
      "[LightGBM] [Info] Number of data points in the train set: 1512, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.109788 -> initscore=-2.092905\n",
      "[LightGBM] [Info] Start training from score -2.092905\n",
      "[LightGBM] [Info] Number of positive: 166, number of negative: 1346\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 953\n",
      "[LightGBM] [Info] Number of data points in the train set: 1512, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.109788 -> initscore=-2.092905\n",
      "[LightGBM] [Info] Start training from score -2.092905\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 166, number of negative: 1346\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000438 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 952\n",
      "[LightGBM] [Info] Number of data points in the train set: 1512, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.109788 -> initscore=-2.092905\n",
      "[LightGBM] [Info] Start training from score -2.092905\n",
      "[LightGBM] [Info] Number of positive: 166, number of negative: 1346\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000526 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 953\n",
      "[LightGBM] [Info] Number of data points in the train set: 1512, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.109788 -> initscore=-2.092905\n",
      "[LightGBM] [Info] Start training from score -2.092905\n",
      "[LightGBM] [Info] Number of positive: 166, number of negative: 1346\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000561 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 953\n",
      "[LightGBM] [Info] Number of data points in the train set: 1512, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.109788 -> initscore=-2.092905\n",
      "[LightGBM] [Info] Start training from score -2.092905\n",
      "[LightGBM] [Info] Number of positive: 166, number of negative: 1346\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 952\n",
      "[LightGBM] [Info] Number of data points in the train set: 1512, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.109788 -> initscore=-2.092905\n",
      "[LightGBM] [Info] Start training from score -2.092905\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 165, number of negative: 1347\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000561 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 1512, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.109127 -> initscore=-2.099690\n",
      "[LightGBM] [Info] Start training from score -2.099690\n",
      "[LightGBM] [Info] Number of positive: 165, number of negative: 1347\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000555 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 950\n",
      "[LightGBM] [Info] Number of data points in the train set: 1512, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.109127 -> initscore=-2.099690\n",
      "[LightGBM] [Info] Start training from score -2.099690\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 165, number of negative: 1347\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000492 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 947\n",
      "[LightGBM] [Info] Number of data points in the train set: 1512, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.109127 -> initscore=-2.099690\n",
      "[LightGBM] [Info] Start training from score -2.099690\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 165, number of negative: 1347\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000503 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 943\n",
      "[LightGBM] [Info] Number of data points in the train set: 1512, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.109127 -> initscore=-2.099690\n",
      "[LightGBM] [Info] Start training from score -2.099690\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM - Log Loss (10-fold CV): 0.24399230711426467\n",
      "LightGBM - ROC AUC Score (10-fold CV): 0.931480324343176\n",
      "LightGBM - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1496\n",
      "           1       0.71      0.60      0.65       184\n",
      "\n",
      "    accuracy                           0.93      1680\n",
      "   macro avg       0.83      0.79      0.81      1680\n",
      "weighted avg       0.93      0.93      0.93      1680\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the processed dataset\n",
    "file_path = 'model_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Create the target variable based on shot_outcome\n",
    "data['shot_outcome'] = data['shot_outcome'].apply(lambda x: 1 if x == 'Goal' else 0)\n",
    "\n",
    "# Drop the columns that are not needed for the model\n",
    "data = data.drop(columns=['location', 'period', 'statsbomb_xg', 'possession_team', 'player'])\n",
    "\n",
    "# Handle categorical variables including 'position'\n",
    "data = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "# Define the features and target variable\n",
    "X = data.drop(columns=['shot_outcome'])\n",
    "y = data['shot_outcome']\n",
    "\n",
    "# Scale the features using Standard scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Function to evaluate models using cross-validation\n",
    "def evaluate_model_cv(model, X, y):\n",
    "    y_pred_prob = cross_val_predict(model, X, y, cv=10, method='predict_proba')[:, 1]\n",
    "    log_loss_score = log_loss(y, y_pred_prob)\n",
    "    roc_auc = roc_auc_score(y, y_pred_prob)\n",
    "    y_pred = cross_val_predict(model, X, y, cv=10)\n",
    "    report = classification_report(y, y_pred)\n",
    "    \n",
    "    return log_loss_score, roc_auc, report\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "log_loss_lr, roc_auc_lr, report_lr = evaluate_model_cv(lr_model, X_scaled, y)\n",
    "print(f'Logistic Regression - Log Loss (10-fold CV): {log_loss_lr}')\n",
    "print(f'Logistic Regression - ROC AUC Score (10-fold CV): {roc_auc_lr}')\n",
    "print('Logistic Regression - Classification Report:')\n",
    "print(report_lr)\n",
    "\n",
    "# XGBoost\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "log_loss_xgb, roc_auc_xgb, report_xgb = evaluate_model_cv(xgb_model, X_scaled, y)\n",
    "print(f'XGBoost - Log Loss (10-fold CV): {log_loss_xgb}')\n",
    "print(f'XGBoost - ROC AUC Score (10-fold CV): {roc_auc_xgb}')\n",
    "print('XGBoost - Classification Report:')\n",
    "print(report_xgb)\n",
    "\n",
    "# CatBoost\n",
    "catboost_model = CatBoostClassifier(verbose=0)\n",
    "log_loss_cat, roc_auc_cat, report_cat = evaluate_model_cv(catboost_model, X_scaled, y)\n",
    "print(f'CatBoost - Log Loss (10-fold CV): {log_loss_cat}')\n",
    "print(f'CatBoost - ROC AUC Score (10-fold CV): {roc_auc_cat}')\n",
    "print('CatBoost - Classification Report:')\n",
    "print(report_cat)\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "log_loss_rf, roc_auc_rf, report_rf = evaluate_model_cv(rf_model, X_scaled, y)\n",
    "print(f'Random Forest - Log Loss (10-fold CV): {log_loss_rf}')\n",
    "print(f'Random Forest - ROC AUC Score (10-fold CV): {roc_auc_rf}')\n",
    "print('Random Forest - Classification Report:')\n",
    "print(report_rf)\n",
    "\n",
    "# LightGBM\n",
    "lgb_model = lgb.LGBMClassifier()\n",
    "log_loss_lgb, roc_auc_lgb, report_lgb = evaluate_model_cv(lgb_model, X_scaled, y)\n",
    "print(f'LightGBM - Log Loss (10-fold CV): {log_loss_lgb}')\n",
    "print(f'LightGBM - ROC AUC Score (10-fold CV): {roc_auc_lgb}')\n",
    "print('LightGBM - Classification Report:')\n",
    "print(report_lgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TUNED MODELS\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning)  # Suppress specific warnings\n",
    "\n",
    "# Load the processed dataset\n",
    "file_path = 'model_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Create the target variable based on shot_outcome\n",
    "data['shot_outcome'] = data['shot_outcome'].apply(lambda x: 1 if x == 'Goal' else 0)\n",
    "\n",
    "# Drop the columns that are not needed for the model\n",
    "data = data.drop(columns=['location', 'period', 'statsbomb_xg', 'possession_team', 'player'])\n",
    "\n",
    "# Handle categorical variables including 'position'\n",
    "data = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "# Define the features and target variable\n",
    "X = data.drop(columns=['shot_outcome'])\n",
    "y = data['shot_outcome']\n",
    "\n",
    "# Scale the features using Standard scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Function to evaluate models using cross-validation\n",
    "def evaluate_model_cv(model, X, y):\n",
    "    y_pred_prob = cross_val_predict(model, X, y, cv=10, method='predict_proba')[:, 1]\n",
    "    log_loss_score = log_loss(y, y_pred_prob)\n",
    "    roc_auc = roc_auc_score(y, y_pred_prob)\n",
    "    y_pred = cross_val_predict(model, X, y, cv=10)\n",
    "    report = classification_report(y, y_pred)\n",
    "    \n",
    "    return log_loss_score, roc_auc, report\n",
    "\n",
    "# Hyperparameter grids\n",
    "param_grid_lr = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'saga']\n",
    "}\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 6]\n",
    "}\n",
    "\n",
    "param_grid_catboost = {\n",
    "    'iterations': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'depth': [3, 6]\n",
    "}\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "param_grid_lgb = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'num_leaves': [31, 50],\n",
    "    'min_child_samples': [20, 30],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "grid_search_lr = GridSearchCV(lr_model, param_grid_lr, cv=10, scoring='neg_log_loss')\n",
    "log_loss_lr, roc_auc_lr, report_lr = evaluate_model_cv(grid_search_lr, X_scaled, y)\n",
    "print(f'Logistic Regression - Log Loss (10-fold CV): {log_loss_lr}')\n",
    "print(f'Logistic Regression - ROC AUC Score (10-fold CV): {roc_auc_lr}')\n",
    "print('Logistic Regression - Classification Report:')\n",
    "print(report_lr)\n",
    "\n",
    "# XGBoost\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "grid_search_xgb = GridSearchCV(xgb_model, param_grid_xgb, cv=10, scoring='neg_log_loss')\n",
    "log_loss_xgb, roc_auc_xgb, report_xgb = evaluate_model_cv(grid_search_xgb, X_scaled, y)\n",
    "print(f'XGBoost - Log Loss (10-fold CV): {log_loss_xgb}')\n",
    "print(f'XGBoost - ROC AUC Score (10-fold CV): {roc_auc_xgb}')\n",
    "print('XGBoost - Classification Report:')\n",
    "print(report_xgb)\n",
    "\n",
    "# CatBoost\n",
    "catboost_model = CatBoostClassifier(verbose=0)\n",
    "grid_search_catboost = GridSearchCV(catboost_model, param_grid_catboost, cv=10, scoring='neg_log_loss')\n",
    "log_loss_cat, roc_auc_cat, report_cat = evaluate_model_cv(grid_search_catboost, X_scaled, y)\n",
    "print(f'CatBoost - Log Loss (10-fold CV): {log_loss_cat}')\n",
    "print(f'CatBoost - ROC AUC Score (10-fold CV): {roc_auc_cat}')\n",
    "print('CatBoost - Classification Report:')\n",
    "print(report_cat)\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "grid_search_rf = GridSearchCV(rf_model, param_grid_rf, cv=10, scoring='neg_log_loss')\n",
    "log_loss_rf, roc_auc_rf, report_rf = evaluate_model_cv(grid_search_rf, X_scaled, y)\n",
    "print(f'Random Forest - Log Loss (10-fold CV): {log_loss_rf}')\n",
    "print(f'Random Forest - ROC AUC Score (10-fold CV): {roc_auc_rf}')\n",
    "print('Random Forest - Classification Report:')\n",
    "print(report_rf)\n",
    "\n",
    "# LightGBM\n",
    "lgb_model = lgb.LGBMClassifier()\n",
    "grid_search_lgb = GridSearchCV(lgb_model, param_grid_lgb, cv=10, scoring='neg_log_loss')\n",
    "log_loss_lgb, roc_auc_lgb, report_lgb = evaluate_model_cv(grid_search_lgb, X_scaled, y)\n",
    "print(f'LightGBM - Log Loss (10-fold CV): {log_loss_lgb}')\n",
    "print(f'LightGBM - ROC AUC Score (10-fold CV): {roc_auc_lgb}')\n",
    "print('LightGBM - Classification Report:')\n",
    "print(report_lgb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
